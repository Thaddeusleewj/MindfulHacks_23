{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stu-kalebnim\\Documents\\GitHub\\MindfulHacks_23\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load .env variables\n",
    "from dotenv import load_dotenv\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "# Cassandra), and OpenAI (to generate embeddings)\n",
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# These are used to authenticate with Astra DB\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "\n",
    "# Support for dataset retrieval with Hugging Face\n",
    "from datasets import load_dataset\n",
    "\n",
    "import json\n",
    "import os \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "# Set up the OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VectorStore Long term memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embedding_size = 1536 # Dimensions of the OpenAIEmbeddings\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "embedding_fn = OpenAIEmbeddings().embed_query\n",
    "vectorstore = FAISS(embedding_fn, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In actual usage, you would set `k` to be a higher value, but we use k=1 to show that\n",
    "# the vector lookup still returns the semantically relevant information\n",
    "retriever = vectorstore.as_retriever(search_kwargs=dict(k=1))\n",
    "memory = VectorStoreRetrieverMemory(retriever=retriever)\n",
    "\n",
    "# When added to an agent, the memory object can save pertinent information from conversations or used tools\n",
    "memory.save_context({\"input\": \"My favorite food is pizza\"}, {\"output\": \"that's good to know\"})\n",
    "memory.save_context({\"input\": \"My favorite sport is soccer\"}, {\"output\": \"...\"})\n",
    "memory.save_context({\"input\": \"I don't the Celtics\"}, {\"output\": \"ok\"}) #\n",
    "\n",
    "memory.sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Relevant pieces of previous conversation:\n",
      "input: My favorite food is pizza\n",
      "output: that's good to know\n",
      "\n",
      "(You do not need to use these pieces of information if not relevant)\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Perry, what's up?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi Perry, I'm doing great. How about you?\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0) # Can be any valid LLM\n",
    "_DEFAULT_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Relevant pieces of previous conversation:\n",
    "{history}\n",
    "\n",
    "(You do not need to use these pieces of information if not relevant)\n",
    "\n",
    "Current conversation:\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"], template=_DEFAULT_TEMPLATE\n",
    ")\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=llm, \n",
    "    prompt=PROMPT,\n",
    "    # We set a very low max_token_limit for the purposes of testing.\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "conversation_with_summary.predict(input=\"Hi, my name is Perry, what's up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Relevant pieces of previous conversation:\n",
      "input: My favorite sport is soccer\n",
      "output: ...\n",
      "\n",
      "(You do not need to use these pieces of information if not relevant)\n",
      "\n",
      "Current conversation:\n",
      "Human: what's my favorite sport?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' You told me earlier that your favorite sport is soccer.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, the basketball related content is surfaced\n",
    "conversation_with_summary.predict(input=\"what's my favorite sport?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting from Supabase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-08 08:13:02,530:INFO - HTTP Request: GET https://xateluqtqxktrcaeqmlz.supabase.co/rest/v1/therapy?select=%2A&order=created_at.desc \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key_points_dict:  {'MainProblems': 'Feeling stressed about school and the transition to adulthood. Unsure about going to college right away or taking a gap year.', 'AnythingRelevant': 'Pressure from parents and teachers to pursue a traditional academic path. Fear of making the wrong decision and disappointing others.'}\n",
      "checkUp_questions:  {'Question1': 'What goals and objectives would you like to set related to your stress about school and the transition to adulthood?', 'Question2': 'How do you think you should prioritize and organize your thoughts and ideas to effectively solve the problem of deciding whether to go to college right away or take a gap year?'}\n"
     ]
    }
   ],
   "source": [
    "from llm.main import TherapistLLM\n",
    "# Supabase\n",
    "SUPABASE_URL=\"https://xateluqtqxktrcaeqmlz.supabase.co\"\n",
    "SUPABASE_KEY=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InhhdGVsdXF0cXhrdHJjYWVxbWx6Iiwicm9sZSI6ImFub24iLCJpYXQiOjE2OTY2Njc1MzIsImV4cCI6MjAxMjI0MzUzMn0.fKeq_LSYQxM21EY2o5mCxbg9rA9rFqvBuyexXuOpQMo\"\n",
    "\n",
    "therapistLLM = TherapistLLM(SUPABASE_URL=SUPABASE_URL, SUPABASE_KEY=SUPABASE_KEY)\n",
    "checkup_question = therapistLLM.get_checkUp_question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "follow_up_checkUp_advice:  {'Advice1': \"Based on your history and current reflection, it seems like you have been doing a great job of allowing yourself to feel your emotions and release them in a healthy way. It's important to continue this process of self-expression and self-care. As for the journal prompt, I would recommend reflecting on how journaling has been helping you and explore other ways you can continue to process your emotions effectively. Can you think of any activities or practices that might provide the same sense of release and relief as journaling?\", 'Advice2': 'Additionally, considering your main problems of MainProblems, it could be beneficial to reflect on how your stress about school and the transition to adulthood may be impacting your emotional well-being. How do you currently cope with these stressors, and are there any strategies or resources you can explore to better manage them?'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Advice1': \"Based on your history and current reflection, it seems like you have been doing a great job of allowing yourself to feel your emotions and release them in a healthy way. It's important to continue this process of self-expression and self-care. As for the journal prompt, I would recommend reflecting on how journaling has been helping you and explore other ways you can continue to process your emotions effectively. Can you think of any activities or practices that might provide the same sense of release and relief as journaling?\",\n",
       " 'Advice2': 'Additionally, considering your main problems of MainProblems, it could be beneficial to reflect on how your stress about school and the transition to adulthood may be impacting your emotional well-being. How do you currently cope with these stressors, and are there any strategies or resources you can explore to better manage them?'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "followUpAdvice = therapistLLM.get_follow_up_checkUp_advice(user_response= \"One of the first things I've done is just let myself feel it all. You know, it's important to admit that breakup pain and sadness are real, and it's okay to let it out. I've shed some tears, maybe screamed into a pillow a couple of times, and even scribbled down my feelings in this journal. It's like this journal has become my go-to friend to vent to. Getting all those emotions out has honestly been a big relief.\")\n",
    "followUpAdvice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and a theripist. The theripist is meant to help the human with her mental health issues in a positive manner, giving inspirational advice with relevance to the context of the human. If the theripist does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Relevant pieces of previous conversation:\n",
      "input: I'm feeling sad today,my exams are coming up and I'm not prepared at all\n",
      "response:  I understand how you feel. It can be really overwhelming when you have a lot of exams coming up and you don't feel prepared. Have you been studying for them? What can I do to help you?\n",
      "input: I'm feeling sad today,my exams are coming up and I'm not prepared at all\n",
      "output:  I understand how you feel. It can be really overwhelming when you have a lot of exams coming up and you don't feel prepared. Have you been studying for them? What can I do to help you?\n",
      "input: My problem is I very sad due to a breakup with my girlfriend\n",
      "output: Oh, I'm so sorry to hear that, that can be really tough. Want to talk about it? I’m happy to lend an ear. Was it a mutual decision or a difficult break up?\n",
      "\n",
      "(You do not need to use these pieces of information if not relevant)\n",
      "\n",
      "Current conversation:\n",
      "Human: yeah, I've been studying but i cant perform due to my situation at home, my parents keep arguging\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I'm sorry to hear that. It can be really difficult to focus on studying when there is a lot of tension at home. Is there anything I can do to help you? Do you have any support system you can rely on?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "therapistLLM.chat(\"yeah, I've been studying but i cant perform due to my situation at home, my parents keep arguging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and a theripist. The theripist is meant to help the human with her mental health issues in a positive manner, giving inspirational advice with relevance to the context of the human. If the theripist does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Relevant pieces of previous conversation:\n",
      "input: I'm feeling sad today,my exams are coming up and I'm not prepared at all\n",
      "response:  I understand how you feel. It can be really overwhelming when you have a lot of exams coming up and you don't feel prepared. Have you been studying for them? What can I do to help you?\n",
      "input: My problem is I very sad due to a breakup with my girlfriend\n",
      "output: Oh, I'm so sorry to hear that, that can be really tough. Want to talk about it? I’m happy to lend an ear. Was it a mutual decision or a difficult break up?\n",
      "input: My problem is I very sad due to a breakup with my girlfriend\n",
      "output: Oh, I'm so sorry to hear that, that can be really tough. Want to talk about it? I’m happy to lend an ear. Was it a mutual decision or a difficult break up?\n",
      "\n",
      "(You do not need to use these pieces of information if not relevant)\n",
      "\n",
      "Current conversation:\n",
      "Human: Just talk to me, give me advice on what to due\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Sure, I'm here to listen and offer advice. What do you think would be the best way to move forward from this breakup? Have you thought about talking to a friend or family member about it? It can be really helpful to have someone to talk to about these things.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "therapistLLM.chat(\"Just talk to me, give me advice on what to due\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetrieverMemory(retriever=VectorStoreRetriever(tags=['FAISS'], vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x000001A402B03B20>, search_kwargs={'k': 3}))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "therapistLLM.memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
