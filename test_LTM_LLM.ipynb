{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stu-kalebnim\\Documents\\GitHub\\MindfulHacks_23\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load .env variables\n",
    "from dotenv import load_dotenv\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "# Cassandra), and OpenAI (to generate embeddings)\n",
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# These are used to authenticate with Astra DB\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "\n",
    "# Support for dataset retrieval with Hugging Face\n",
    "from datasets import load_dataset\n",
    "\n",
    "import json\n",
    "import os \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "# Set up the OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VectorStore Long term memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embedding_size = 1536 # Dimensions of the OpenAIEmbeddings\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "embedding_fn = OpenAIEmbeddings().embed_query\n",
    "vectorstore = FAISS(embedding_fn, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In actual usage, you would set `k` to be a higher value, but we use k=1 to show that\n",
    "# the vector lookup still returns the semantically relevant information\n",
    "retriever = vectorstore.as_retriever(search_kwargs=dict(k=1))\n",
    "memory = VectorStoreRetrieverMemory(retriever=retriever)\n",
    "\n",
    "# When added to an agent, the memory object can save pertinent information from conversations or used tools\n",
    "memory.save_context({\"input\": \"My favorite food is pizza\"}, {\"output\": \"that's good to know\"})\n",
    "memory.save_context({\"input\": \"My favorite sport is soccer\"}, {\"output\": \"...\"})\n",
    "memory.save_context({\"input\": \"I don't the Celtics\"}, {\"output\": \"ok\"}) #\n",
    "\n",
    "memory.sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Relevant pieces of previous conversation:\n",
      "input: My favorite food is pizza\n",
      "output: that's good to know\n",
      "\n",
      "(You do not need to use these pieces of information if not relevant)\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Perry, what's up?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi Perry, I'm doing great. How about you?\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0) # Can be any valid LLM\n",
    "_DEFAULT_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Relevant pieces of previous conversation:\n",
    "{history}\n",
    "\n",
    "(You do not need to use these pieces of information if not relevant)\n",
    "\n",
    "Current conversation:\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"], template=_DEFAULT_TEMPLATE\n",
    ")\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=llm, \n",
    "    prompt=PROMPT,\n",
    "    # We set a very low max_token_limit for the purposes of testing.\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "conversation_with_summary.predict(input=\"Hi, my name is Perry, what's up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Relevant pieces of previous conversation:\n",
      "input: My favorite sport is soccer\n",
      "output: ...\n",
      "\n",
      "(You do not need to use these pieces of information if not relevant)\n",
      "\n",
      "Current conversation:\n",
      "Human: what's my favorite sport?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' You told me earlier that your favorite sport is soccer.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, the basketball related content is surfaced\n",
    "conversation_with_summary.predict(input=\"what's my favorite sport?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stu-kalebnim\\Documents\\GitHub\\MindfulHacks_23\\env\\lib\\site-packages\\pinecone\\index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting from Supabase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-08 05:30:16,921:INFO - HTTP Request: GET https://xateluqtqxktrcaeqmlz.supabase.co/rest/v1/therapy?select=%2A&order=created_at.desc \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key_points_dict:  {'MainProblems': 'Broke up with girlfriend recently', 'AnythingRelevant': 'Feeling devastated, numb, and in disbelief about the breakup. Struggling with self-blame and feeling like friends and family were right about warning signs. Finding it difficult to move on and constantly reminded of the past. Struggling with loss of appetite and sleep. Some hobbies bring back memories of the ex-girlfriend.'}\n",
      "checkUp_questions:  {'Question1': 'What goals and objectives would you like to set in order to overcome the challenges and emotions related to your recent breakup?', 'Question2': 'How do you think you can prioritize and organize your thoughts and ideas to effectively move forward from this breakup?', 'Question3': 'What are some things you did today that you can be proud of?'}\n"
     ]
    }
   ],
   "source": [
    "from llm.main import TherapistLLM\n",
    "# Supabase\n",
    "SUPABASE_URL=\"https://xateluqtqxktrcaeqmlz.supabase.co\"\n",
    "SUPABASE_KEY=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InhhdGVsdXF0cXhrdHJjYWVxbWx6Iiwicm9sZSI6ImFub24iLCJpYXQiOjE2OTY2Njc1MzIsImV4cCI6MjAxMjI0MzUzMn0.fKeq_LSYQxM21EY2o5mCxbg9rA9rFqvBuyexXuOpQMo\"\n",
    "\n",
    "therapistLLM = TherapistLLM(SUPABASE_URL=SUPABASE_URL, SUPABASE_KEY=SUPABASE_KEY)\n",
    "checkup_question = therapistLLM.get_checkUp_question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "follow_up_checkUp_advice:  {'Advice1': \"One of the first steps in overcoming the challenges and emotions related to your recent breakup is to allow yourself to feel and express your emotions. It's important to acknowledge that breakup pain and sadness are real, and it's okay to let it out. Continue to use your journal as a safe space to vent and process your feelings. Write down your emotions and experiences, and use this journal as your go-to friend to confide in. This practice can bring a big sense of relief and help you on your journey of healing.\"}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Advice2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\MindfulHacks_23\\test_LTM_LLM.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/MindfulHacks_23/test_LTM_LLM.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m followUpAdvice \u001b[39m=\u001b[39m therapistLLM\u001b[39m.\u001b[39;49mget_follow_up_checkUp_advice(user_response\u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mOne of the first things I\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mve done is just let myself feel it all. You know, it\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ms important to admit that breakup pain and sadness are real, and it\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ms okay to let it out. I\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mve shed some tears, maybe screamed into a pillow a couple of times, and even scribbled down my feelings in this journal. It\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ms like this journal has become my go-to friend to vent to. Getting all those emotions out has honestly been a big relief.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/MindfulHacks_23/test_LTM_LLM.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m followUpAdvice\n",
      "File \u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\MindfulHacks_23\\llm\\main.py:221\u001b[0m, in \u001b[0;36mTherapistLLM.get_follow_up_checkUp_advice\u001b[1;34m(self, user_response)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mfollow_up_checkUp_advice: \u001b[39m\u001b[39m'\u001b[39m, follow_up_checkUp_advice)\n\u001b[0;32m    220\u001b[0m \u001b[39m# Update the latest journal prompt\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdateLatestJournalPrompt(JournalPrompt1 \u001b[39m=\u001b[39m follow_up_checkUp_advice[\u001b[39m\"\u001b[39m\u001b[39mAdvice1\u001b[39m\u001b[39m\"\u001b[39m],JournalPrompt2 \u001b[39m=\u001b[39m follow_up_checkUp_advice[\u001b[39m\"\u001b[39;49m\u001b[39mAdvice2\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m    224\u001b[0m \u001b[39m# TODO \u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[39m#(f\"This is the follow up check up Advice1 based on :checkup{checkUp_question}\", f\"This is follow up check up Advice2 and user_response-->{user_response}\")\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[39mreturn\u001b[39;00m follow_up_checkUp_advice\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Advice2'"
     ]
    }
   ],
   "source": [
    "followUpAdvice = therapistLLM.get_follow_up_checkUp_advice(user_response= \"One of the first things I've done is just let myself feel it all. You know, it's important to admit that breakup pain and sadness are real, and it's okay to let it out. I've shed some tears, maybe screamed into a pillow a couple of times, and even scribbled down my feelings in this journal. It's like this journal has become my go-to friend to vent to. Getting all those emotions out has honestly been a big relief.\")\n",
    "followUpAdvice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and a theripist. The theripist is meant to help the human with her mental health issues in a positive manner, giving inspirational advice with relevance to the context of the human. If the theripist does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Relevant pieces of previous conversation:\n",
      "input: I'm feeling sad today,my exams are coming up and I'm not prepared at all\n",
      "response:  I understand how you feel. It can be really overwhelming when you have a lot of exams coming up and you don't feel prepared. Have you been studying for them? What can I do to help you?\n",
      "input: I'm feeling sad today,my exams are coming up and I'm not prepared at all\n",
      "output:  I understand how you feel. It can be really overwhelming when you have a lot of exams coming up and you don't feel prepared. Have you been studying for them? What can I do to help you?\n",
      "input: My problem is I very sad due to a breakup with my girlfriend\n",
      "output: Oh, I'm so sorry to hear that, that can be really tough. Want to talk about it? I’m happy to lend an ear. Was it a mutual decision or a difficult break up?\n",
      "\n",
      "(You do not need to use these pieces of information if not relevant)\n",
      "\n",
      "Current conversation:\n",
      "Human: yeah, I've been studying but i cant perform due to my situation at home, my parents keep arguging\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I'm sorry to hear that. It can be really difficult to focus on studying when there is a lot of tension at home. Is there anything I can do to help you? Do you have any support system you can rely on?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "therapistLLM.chat(\"yeah, I've been studying but i cant perform due to my situation at home, my parents keep arguging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and a theripist. The theripist is meant to help the human with her mental health issues in a positive manner, giving inspirational advice with relevance to the context of the human. If the theripist does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Relevant pieces of previous conversation:\n",
      "input: I'm feeling sad today,my exams are coming up and I'm not prepared at all\n",
      "response:  I understand how you feel. It can be really overwhelming when you have a lot of exams coming up and you don't feel prepared. Have you been studying for them? What can I do to help you?\n",
      "input: My problem is I very sad due to a breakup with my girlfriend\n",
      "output: Oh, I'm so sorry to hear that, that can be really tough. Want to talk about it? I’m happy to lend an ear. Was it a mutual decision or a difficult break up?\n",
      "input: My problem is I very sad due to a breakup with my girlfriend\n",
      "output: Oh, I'm so sorry to hear that, that can be really tough. Want to talk about it? I’m happy to lend an ear. Was it a mutual decision or a difficult break up?\n",
      "\n",
      "(You do not need to use these pieces of information if not relevant)\n",
      "\n",
      "Current conversation:\n",
      "Human: Just talk to me, give me advice on what to due\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Sure, I'm here to listen and offer advice. What do you think would be the best way to move forward from this breakup? Have you thought about talking to a friend or family member about it? It can be really helpful to have someone to talk to about these things.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "therapistLLM.chat(\"Just talk to me, give me advice on what to due\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetrieverMemory(retriever=VectorStoreRetriever(tags=['FAISS'], vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x000001A402B03B20>, search_kwargs={'k': 3}))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "therapistLLM.memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
