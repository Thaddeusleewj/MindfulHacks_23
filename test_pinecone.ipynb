{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "import openai\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Langchain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# Load variables from the .env file\n",
    "load_dotenv('./Sn33k/.env')\n",
    "\n",
    "# Access the variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "PINECONE_ENVIRONMENT= os.getenv(\"PINECONE_ENVIRONMENT\")\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_description:  IndexDescription(name='mindfulhack', metric='cosine', replicas=1, dimension=1536.0, shards=1, pods=1, pod_type='starter', status={'ready': True, 'state': 'Ready'}, metadata_config=None, source_collection='')\n",
      "index_stats_response:  {'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0}\n"
     ]
    }
   ],
   "source": [
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
    "    environment=PINECONE_ENVIRONMENT,  # next to api key in console\n",
    ")\n",
    "\n",
    "index_name = \"mindfulhack\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
    "# if you already have an index, you can load it like this\n",
    "docsearch = Pinecone.from_existing_index(index_name, embeddings)\n",
    "\n",
    "# List all indexes information\n",
    "index_description = pinecone.describe_index(index_name)\n",
    "print('index_description: ', index_description)\n",
    "\n",
    "index = pinecone.Index(index_name) \n",
    "index_stats_response = index.describe_index_stats()\n",
    "print('index_stats_response: ', index_stats_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test QAChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stu-kalebnim\\Documents\\GitHub\\MindfulHacks_23\\env\\lib\\site-packages\\langchain\\vectorstores\\pinecone.py:59: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_stats_response:  {'dimension': 1536,\n",
      " 'index_fullness': 0.00187,\n",
      " 'namespaces': {'': {'vector_count': 187}},\n",
      " 'total_vector_count': 187}\n",
      "index_description:  IndexDescription(name='mindfulhack', metric='cosine', replicas=1, dimension=1536.0, shards=1, pods=1, pod_type='starter', status={'ready': True, 'state': 'Ready'}, metadata_config=None, source_collection='')\n"
     ]
    }
   ],
   "source": [
    "from llm.chains import QAretrivalChain\n",
    "from pineconeManager.Retrival import PineconeRetrival\n",
    "PINECONE_API_KEY = \"1b1d5b95-2f20-476d-baa8-458cf5779640\"\n",
    "PINECONE_INDEX_NAME = \"mindfulhack\"\n",
    "PINECONE_ENVIRONMENT=\"gcp-starter\"\n",
    "\n",
    "pineconeRetrival = PineconeRetrival(PINECONE_API_KEY=PINECONE_API_KEY, INDEX_NAME=PINECONE_INDEX_NAME, PINECONE_ENVIRONMENT=PINECONE_ENVIRONMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pineconeManager.Retrival.PineconeRetrival at 0x1bf9926eb00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pineconeRetrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\MindfulHacks_23\\test_pinecone.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/MindfulHacks_23/test_pinecone.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pineconeRetrival\u001b[39m.\u001b[39;49mgetPineconeRelevantDocuments(\u001b[39m\"\u001b[39;49m\u001b[39mWhat problems do I face?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\MindfulHacks_23\\pineconeManager\\Retrival.py:35\u001b[0m, in \u001b[0;36mPineconeRetrival.getPineconeRelevantDocuments\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39mParameters:\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m    query (str): query to search for relevant documents in database\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39mReturns:\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[39m    relevant_documents (str): relevant documents in database based on query\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     34\u001b[0m relevant_documents \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 35\u001b[0m matched_docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretriever\u001b[39m.\u001b[39;49mget_relevant_documents(query)\n\u001b[0;32m     37\u001b[0m \u001b[39mfor\u001b[39;00m i, d \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(matched_docs):\n\u001b[0;32m     38\u001b[0m     \u001b[39m# print(f\"\\n## Document {i}\\n\")\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[39m# print(d.page_content)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     relevant_documents \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m## Document \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00md\u001b[39m.\u001b[39mpage_content\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\MindfulHacks_23\\env\\lib\\site-packages\\langchain\\schema\\retriever.py:211\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[1;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    210\u001b[0m     run_manager\u001b[39m.\u001b[39mon_retriever_error(e)\n\u001b[1;32m--> 211\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    212\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     run_manager\u001b[39m.\u001b[39mon_retriever_end(\n\u001b[0;32m    214\u001b[0m         result,\n\u001b[0;32m    215\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    216\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\MindfulHacks_23\\env\\lib\\site-packages\\langchain\\schema\\retriever.py:204\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[1;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m _kwargs \u001b[39m=\u001b[39m kwargs \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expects_other_args \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m    203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new_arg_supported:\n\u001b[1;32m--> 204\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_relevant_documents(\n\u001b[0;32m    205\u001b[0m         query, run_manager\u001b[39m=\u001b[39mrun_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_kwargs\n\u001b[0;32m    206\u001b[0m     )\n\u001b[0;32m    207\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_relevant_documents(query, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\MindfulHacks_23\\env\\lib\\site-packages\\langchain\\schema\\vectorstore.py:594\u001b[0m, in \u001b[0;36mVectorStoreRetriever._get_relevant_documents\u001b[1;34m(self, query, run_manager)\u001b[0m\n\u001b[0;32m    592\u001b[0m     docs \u001b[39m=\u001b[39m [doc \u001b[39mfor\u001b[39;00m doc, _ \u001b[39min\u001b[39;00m docs_and_similarities]\n\u001b[0;32m    593\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmmr\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 594\u001b[0m     docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectorstore\u001b[39m.\u001b[39mmax_marginal_relevance_search(\n\u001b[0;32m    595\u001b[0m         query, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_kwargs\n\u001b[0;32m    596\u001b[0m     )\n\u001b[0;32m    597\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msearch_type of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_type\u001b[39m}\u001b[39;00m\u001b[39m not allowed.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\MindfulHacks_23\\env\\lib\\site-packages\\langchain\\vectorstores\\pinecone.py:327\u001b[0m, in \u001b[0;36mPinecone.max_marginal_relevance_search\u001b[1;34m(self, query, k, fetch_k, lambda_mult, filter, namespace, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmax_marginal_relevance_search\u001b[39m(\n\u001b[0;32m    302\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    303\u001b[0m     query: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    310\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[0;32m    311\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return docs selected using the maximal marginal relevance.\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \n\u001b[0;32m    313\u001b[0m \u001b[39m    Maximal marginal relevance optimizes for similarity to query AND diversity\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39m        List of Documents selected by maximal marginal relevance.\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 327\u001b[0m     embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embed_query(query)\n\u001b[0;32m    328\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_marginal_relevance_search_by_vector(\n\u001b[0;32m    329\u001b[0m         embedding, k, fetch_k, lambda_mult, \u001b[39mfilter\u001b[39m, namespace\n\u001b[0;32m    330\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\MindfulHacks_23\\env\\lib\\site-packages\\langchain\\vectorstores\\pinecone.py:91\u001b[0m, in \u001b[0;36mPinecone._embed_query\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding, Embeddings):\n\u001b[0;32m     90\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding\u001b[39m.\u001b[39membed_query(text)\n\u001b[1;32m---> 91\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding(text)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "pineconeRetrival.getPineconeRelevantDocuments(\"What problems do I face?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert shit into Pinecone testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting: Iâ€™m here to help. Whatâ€™s g...\n"
     ]
    }
   ],
   "source": [
    "from pineconeManager.Upsert import PineconeUpsert\n",
    "\n",
    "pineconeUpsert = PineconeUpsert(PINECONE_API_KEY=PINECONE_API_KEY, INDEX_NAME=PINECONE_INDEX_NAME, PINECONE_ENVIRONMENT=PINECONE_ENVIRONMENT)\n",
    "\n",
    "# Read breakup.txt \n",
    "with open('breakup.txt', 'r') as file:\n",
    "    breakup_text = file.read().replace('\\n', '')\n",
    "\n",
    "\n",
    "pineconeUpsert.upsert(text = breakup_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
